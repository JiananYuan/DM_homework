{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253325"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tsfresh as tsf\n",
    "import random\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "df = pd.read_csv(r'C:\\\\Users\\\\Jiananyuan\\Desktop\\\\QuickAccess\\\\DM_homework\\dataset\\\\train.csv')\n",
    "signals = df['heartbeat_signals'].str.split(',', expand=True)\n",
    "signals.insert(0, '', df['label'], allow_duplicates=False)\n",
    "col_names = ['label']\n",
    "for i in range(0, 205):\n",
    "    col_names.append('signal_' + str(i))\n",
    "signals.columns = col_names\n",
    "signals = pd.DataFrame(signals, dtype=np.float64)\n",
    "\n",
    "def signal_enhance(_signal, sigma=0.1):\n",
    "    scalingFactor = np.random.normal(loc=1.0, scale=sigma, size=(1, _signal.shape[1]))\n",
    "    noise = np.matmul(np.ones((_signal.shape[0], 1)), scalingFactor)\n",
    "    return _signal * noise\n",
    "\n",
    "idx_set = signals.query('label==1').index\n",
    "record_label_1 = signals.iloc[idx_set, :].reset_index(drop=True)\n",
    "enhanced_signal_label_1 = record_label_1\n",
    "for i in np.arange(16):\n",
    "    tmp_enhanced_signal_label_1 = signal_enhance(record_label_1)\n",
    "    enhanced_signal_label_1 = pd.concat((enhanced_signal_label_1, \n",
    "                                         tmp_enhanced_signal_label_1), axis=0).reset_index(drop=True)\n",
    "enhanced_signal_label_1['label'] = 1\n",
    "\n",
    "idx_set = signals.query('label==2').index\n",
    "record_label_2 = signals.iloc[idx_set, :].reset_index(drop=True)\n",
    "enhanced_signal_label_2 = record_label_2\n",
    "for i in np.arange(3):\n",
    "    tmp_enhanced_signal_label_2 = signal_enhance(record_label_2)\n",
    "    enhanced_signal_label_2 = pd.concat((enhanced_signal_label_2, tmp_enhanced_signal_label_2), axis=0).reset_index(\n",
    "        drop=True)\n",
    "enhanced_signal_label_2['label'] = 2\n",
    "\n",
    "idx_set = signals.query('label==3').index\n",
    "record_label_3 = signals.iloc[idx_set, :].reset_index(drop=True)\n",
    "enhanced_signal_label_3 = record_label_3\n",
    "for i in np.arange(3):\n",
    "    tmp_enhanced_signal_label_3 = signal_enhance(record_label_3)\n",
    "    enhanced_signal_label_3 = pd.concat((enhanced_signal_label_3, tmp_enhanced_signal_label_3), axis=0).reset_index(\n",
    "        drop=True)\n",
    "enhanced_signal_label_3['label'] = 3\n",
    "\n",
    "idx_set = signals.query('label==0').index\n",
    "record_label_0 = signals.iloc[idx_set, :].reset_index(drop=True)\n",
    "\n",
    "data_train = pd.concat([record_label_0, \n",
    "                        enhanced_signal_label_1, \n",
    "                        enhanced_signal_label_2, \n",
    "                        enhanced_signal_label_3], ignore_index=True)\n",
    "\n",
    "def remove_last_zero(_series):\n",
    "    nps = _series.to_numpy()\n",
    "    zero_begin_idxs = np.arange(nps.shape[0])\n",
    "    for i in np.arange(nps.shape[1])[::-1]:\n",
    "        idxs = np.where(nps[zero_begin_idxs, i] <= 1.e-5)[0]\n",
    "        if idxs.size > 0:\n",
    "            nps[zero_begin_idxs[idxs], i] = np.nan\n",
    "            zero_begin_idxs = zero_begin_idxs[idxs]\n",
    "        else:\n",
    "            break\n",
    "    return pd.DataFrame(nps[:, :], index=_series.index, columns=_series.columns[:])\n",
    "\n",
    "# data_train = remove_last_zero(data_train)\n",
    "\n",
    "# drop_idx = list(data_train.index)\n",
    "# drop_idx = random.sample(drop_idx, 3325)\n",
    "# data_train = data_train.drop(drop_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "data_train = shuffle(data_train)\n",
    "net_train_data = data_train.iloc[:, 1:].to_numpy()\n",
    "net_train_label = data_train.iloc[:, 0].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 205) (200000,) (53325, 205) (53325,)\n"
     ]
    }
   ],
   "source": [
    "train_set = data_train.iloc[:200000, :]\n",
    "test_set = data_train.iloc[200000:, :]\n",
    "\n",
    "train_x = train_set.iloc[:, 1:].to_numpy()\n",
    "train_y = train_set.iloc[:, 0].to_numpy()\n",
    "valid_x = test_set.iloc[:, 1:].to_numpy()\n",
    "valid_y = test_set.iloc[:, 0].to_numpy()\n",
    "\n",
    "# train_data = data_train.iloc[:, 1:]\n",
    "# train_label = data_train.iloc[:, 0]\n",
    "\n",
    "# train_data = data_train.iloc[:, 1:].stack()\n",
    "# train_data = train_data.reset_index()\n",
    "# train_data.rename(columns={\"level_0\": \"id\", \"level_1\": \"time\", 0: \"signals\"}, \n",
    "#                   inplace=True)\n",
    "# train_data[\"signals\"] = train_data[\"signals\"].astype(float)\n",
    "\n",
    "# train_data\n",
    "\n",
    "print(train_x.shape, train_y.shape, valid_x.shape, valid_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9912298 , 0.94353304, 0.7646773 , ...,        nan,        nan,\n",
       "               nan],\n",
       "       [0.9714822 , 0.92896875, 0.57293281, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [0.97579528, 0.93408847, 0.65963666, ...,        nan,        nan,\n",
       "               nan],\n",
       "       ...,\n",
       "       [0.88023307, 0.89468516, 0.89448266, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [0.71712964, 0.68011328, 0.63003724, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [0.84084461, 0.5637697 , 0.63639073, ...,        nan,        nan,\n",
       "               nan]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_label.values.tolist()\n",
    "# net_train_data = train_data.values\n",
    "# net_train_label = train_label.values\n",
    "# net_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=1,\n",
    "                out_channels=64,\n",
    "                kernel_size=7,\n",
    "                stride=1,\n",
    "                padding=3,\n",
    "            ),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, 5, 1, 2),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 256, 3, 1, 1), \n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(), \n",
    "            nn.Conv1d(256, 256, 3, 1, 1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(6400, 4096),\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(4096, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.fc3 = nn.Linear(64, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "#         print(x.size())\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import copy\n",
    "\n",
    "# 训练网络\n",
    "def train_net(net, train_loader, valid_loader, EPOCH=20, LR=1e-5):\n",
    "    # 交叉熵作为损失函数\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Adam 优化器\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=LR)\n",
    "    \n",
    "    # 保留准确率最高的模型\n",
    "    best_state = copy.deepcopy(net.state_dict())\n",
    "    best_acc = 0\n",
    "\n",
    "    for epoch in range(EPOCH):\n",
    "        net.train()\n",
    "        train_l = 0\n",
    "        train_num = 0\n",
    "        for b_x, b_y in train_loader:\n",
    "            output = net(b_x)\n",
    "            loss = loss_fn(output, b_y)\n",
    "            optimizer.zero_grad() \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_l += loss.cpu().item()\n",
    "            train_num += len(b_x)\n",
    "        \n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_l = 0\n",
    "            valid_num = 0\n",
    "            right_num = 0.\n",
    "            for b_x, b_y in valid_loader:\n",
    "                output = net(b_x)\n",
    "                loss = loss_fn(output, b_y)\n",
    "                valid_l += loss.cpu().item()\n",
    "\n",
    "                pred_y = torch.argmax(output, dim=1)\n",
    "                valid_num += len(b_x)\n",
    "                right_num += (pred_y == b_y).sum().item()\n",
    "        valid_acc = right_num / valid_num\n",
    "        if valid_acc >= best_acc:\n",
    "            best_acc = valid_acc\n",
    "            best_state = copy.deepcopy(net.state_dict())\n",
    "        print('Epoch {} | train_loss {:.2e} | valid_loss {:.2e} | acc {:f} | best_acc {:f}'.format(epoch + 1, train_l / train_num, valid_l / valid_num, valid_acc, best_acc))\n",
    "        \n",
    "    \n",
    "    return best_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\jiananyuan\\appdata\\roaming\\python\\python38\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\jiananyuan\\appdata\\roaming\\python\\python38\\site-packages (from imblearn) (0.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\jiananyuan\\appdata\\roaming\\python\\python38\\site-packages (from imbalanced-learn->imblearn) (1.2.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\jiananyuan\\appdata\\roaming\\python\\python38\\site-packages (from imbalanced-learn->imblearn) (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\jiananyuan\\appdata\\roaming\\python\\python38\\site-packages (from imbalanced-learn->imblearn) (1.19.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\jiananyuan\\appdata\\roaming\\python\\python38\\site-packages (from imbalanced-learn->imblearn) (1.10.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([257932, 1, 205]) torch.Size([257932]) torch.Size([25333, 1, 205]) torch.Size([25333])\n",
      "torch.Size([257932, 1, 205]) torch.Size([257932]) torch.Size([25333, 1, 205]) torch.Size([25333])\n",
      "torch.Size([257932, 1, 205]) torch.Size([257932]) torch.Size([25333, 1, 205]) torch.Size([25333])\n",
      "torch.Size([257932, 1, 205]) torch.Size([257932]) torch.Size([25333, 1, 205]) torch.Size([25333])\n",
      "torch.Size([257932, 1, 205]) torch.Size([257932]) torch.Size([25333, 1, 205]) torch.Size([25333])\n",
      "torch.Size([257936, 1, 205]) torch.Size([257936]) torch.Size([25332, 1, 205]) torch.Size([25332])\n",
      "torch.Size([257936, 1, 205]) torch.Size([257936]) torch.Size([25332, 1, 205]) torch.Size([25332])\n",
      "torch.Size([257932, 1, 205]) torch.Size([257932]) torch.Size([25332, 1, 205]) torch.Size([25332])\n",
      "torch.Size([257932, 1, 205]) torch.Size([257932]) torch.Size([25332, 1, 205]) torch.Size([25332])\n",
      "torch.Size([257932, 1, 205]) torch.Size([257932]) torch.Size([25332, 1, 205]) torch.Size([25332])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from torch.utils.data import TensorDataset\n",
    "import time\n",
    "net_states = []\n",
    "seed = 2023\n",
    "\n",
    "# 采用 10 折交叉验证，训练 10 个模型\n",
    "sk = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "for i, (train, valid) in enumerate(sk.split(net_train_data, net_train_label)):\n",
    "    x_train = net_train_data[train]\n",
    "    y_train = net_train_label[train]\n",
    "    x_valid = net_train_data[valid]\n",
    "    y_valid = net_train_label[valid]\n",
    "    \n",
    "    # # 对训练数据进行随机过采样\n",
    "    x_train, y_train = RandomOverSampler(random_state=seed).fit_resample(x_train, y_train)\n",
    "\n",
    "    x_train = torch.tensor(x_train, dtype=torch.float).unsqueeze(-2)\n",
    "    x_valid = torch.tensor(x_valid, dtype=torch.float).unsqueeze(-2)\n",
    "    y_train = torch.tensor(y_train, dtype=int)\n",
    "    y_valid = torch.tensor(y_valid, dtype=int)\n",
    "    \n",
    "    # train_loader = DataLoader(TensorDataset(x_train, y_train), batch_size=512, shuffle=True, num_workers=2)\n",
    "    # valid_loader = DataLoader(TensorDataset(x_valid, y_valid), batch_size=1024, shuffle=False)\n",
    "    \n",
    "    # print('\\nTraining {}th net. {}\\n'.format(i + 1, time.strftime('%H:%M:%S')))\n",
    "    # net = Net()\n",
    "    # s = train_net(net, train_loader, valid_loader, 30)\n",
    "    # net_states.append(s)\n",
    "    print(x_train.shape, y_train.shape, x_valid.shape, y_valid.shape)\n",
    "\n",
    "# 保存模型参数\n",
    "torch.save(net_states, 'net_state.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200000, 1, 205]) torch.Size([200000]) torch.Size([53325, 1, 205]) torch.Size([53325])\n",
      "\n",
      "Training 10th net. 13:22:00\n",
      "\n",
      "Epoch 1 | train_loss 5.94e-04 | valid_loss 1.98e-04 | acc 0.986442 | best_acc 0.986442\n",
      "Epoch 2 | train_loss 3.40e-04 | valid_loss 1.51e-04 | acc 0.992743 | best_acc 0.992743\n",
      "Epoch 3 | train_loss 2.66e-04 | valid_loss 1.24e-04 | acc 0.994955 | best_acc 0.994955\n",
      "Epoch 4 | train_loss 2.16e-04 | valid_loss 1.01e-04 | acc 0.995762 | best_acc 0.995762\n",
      "Epoch 5 | train_loss 1.78e-04 | valid_loss 8.68e-05 | acc 0.996643 | best_acc 0.996643\n",
      "Epoch 6 | train_loss 1.48e-04 | valid_loss 7.30e-05 | acc 0.996981 | best_acc 0.996981\n",
      "Epoch 7 | train_loss 1.25e-04 | valid_loss 6.13e-05 | acc 0.997506 | best_acc 0.997506\n",
      "Epoch 8 | train_loss 1.05e-04 | valid_loss 5.36e-05 | acc 0.997543 | best_acc 0.997543\n",
      "Epoch 9 | train_loss 8.92e-05 | valid_loss 4.48e-05 | acc 0.997731 | best_acc 0.997731\n",
      "Epoch 10 | train_loss 7.57e-05 | valid_loss 4.01e-05 | acc 0.997900 | best_acc 0.997900\n",
      "Epoch 11 | train_loss 6.46e-05 | valid_loss 3.45e-05 | acc 0.998068 | best_acc 0.998068\n",
      "Epoch 12 | train_loss 5.54e-05 | valid_loss 2.98e-05 | acc 0.998050 | best_acc 0.998068\n",
      "Epoch 13 | train_loss 4.75e-05 | valid_loss 2.78e-05 | acc 0.998031 | best_acc 0.998068\n",
      "Epoch 14 | train_loss 4.07e-05 | valid_loss 2.44e-05 | acc 0.998106 | best_acc 0.998106\n",
      "Epoch 15 | train_loss 3.52e-05 | valid_loss 2.23e-05 | acc 0.998125 | best_acc 0.998125\n",
      "Epoch 16 | train_loss 3.02e-05 | valid_loss 1.85e-05 | acc 0.998331 | best_acc 0.998331\n",
      "Epoch 17 | train_loss 2.59e-05 | valid_loss 1.68e-05 | acc 0.998368 | best_acc 0.998368\n",
      "Epoch 18 | train_loss 2.27e-05 | valid_loss 1.51e-05 | acc 0.998500 | best_acc 0.998500\n",
      "Epoch 19 | train_loss 1.94e-05 | valid_loss 1.40e-05 | acc 0.998350 | best_acc 0.998500\n",
      "Epoch 20 | train_loss 1.68e-05 | valid_loss 1.26e-05 | acc 0.998275 | best_acc 0.998500\n",
      "Epoch 21 | train_loss 1.46e-05 | valid_loss 1.17e-05 | acc 0.998425 | best_acc 0.998500\n",
      "Epoch 22 | train_loss 1.27e-05 | valid_loss 1.01e-05 | acc 0.998368 | best_acc 0.998500\n",
      "Epoch 23 | train_loss 1.08e-05 | valid_loss 9.30e-06 | acc 0.998462 | best_acc 0.998500\n",
      "Epoch 24 | train_loss 9.23e-06 | valid_loss 8.84e-06 | acc 0.998425 | best_acc 0.998500\n",
      "Epoch 25 | train_loss 8.06e-06 | valid_loss 8.02e-06 | acc 0.998519 | best_acc 0.998519\n",
      "Epoch 26 | train_loss 1.13e-05 | valid_loss 1.08e-05 | acc 0.997787 | best_acc 0.998519\n",
      "Epoch 27 | train_loss 7.05e-06 | valid_loss 6.97e-06 | acc 0.998425 | best_acc 0.998519\n",
      "Epoch 28 | train_loss 5.29e-06 | valid_loss 6.52e-06 | acc 0.998444 | best_acc 0.998519\n",
      "Epoch 29 | train_loss 4.53e-06 | valid_loss 6.14e-06 | acc 0.998425 | best_acc 0.998519\n",
      "Epoch 30 | train_loss 3.90e-06 | valid_loss 5.80e-06 | acc 0.998500 | best_acc 0.998519\n"
     ]
    }
   ],
   "source": [
    "seed = 2023\n",
    "\n",
    "# x_train, x_label = RandomOverSampler(random_state=seed).fit_resample(x_train, x_label)\n",
    "\n",
    "train_x = torch.tensor(train_x, dtype=torch.float).unsqueeze(-2)\n",
    "valid_x = torch.tensor(valid_x, dtype=torch.float).unsqueeze(-2)\n",
    "train_y = torch.tensor(train_y, dtype=int)\n",
    "valid_y = torch.tensor(valid_y, dtype=int)\n",
    "print(train_x.shape, train_y.shape, valid_x.shape, valid_y.shape)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(train_x, train_y), batch_size=512, shuffle=True, num_workers=2)\n",
    "valid_loader = DataLoader(TensorDataset(valid_x, valid_y), batch_size=1024, shuffle=False)\n",
    "\n",
    "print('\\nTraining {}th net. {}\\n'.format(i + 1, time.strftime('%H:%M:%S')))\n",
    "net = Net()\n",
    "s = train_net(net, train_loader, valid_loader, 30)\n",
    "torch.save(s, 'net_state.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9916, 1.0000, 0.6318,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.6076, 0.5417, 0.3407,  ..., 0.3506, 0.3506, 0.3639]],\n",
       "\n",
       "        [[0.9753, 0.6711, 0.6868,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.9517, 0.9163, 0.6675,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.9277, 0.6772, 0.2429,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.6653, 0.5271, 0.5167,  ..., 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ****************** 以下生成 submit.csv 结果文件 ******************\n",
    "df = pd.read_csv(r'C:\\\\Users\\\\Jiananyuan\\Desktop\\\\QuickAccess\\\\DM_homework\\dataset\\\\testA.csv')\n",
    "test_signals = df['heartbeat_signals'].str.split(',', expand=True)\n",
    "col_names = []\n",
    "for i in range(0, 205):\n",
    "    col_names.append('signal_' + str(i))\n",
    "test_signals.columns = col_names\n",
    "test_signals = pd.DataFrame(test_signals, dtype=np.float64)\n",
    "# test_signals  =remove_last_zero(test_signals)\n",
    "\n",
    "test_signals = torch.tensor(test_signals.to_numpy(), dtype=torch.float).unsqueeze(-2)\n",
    "test_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3, ..., 2, 0, 3], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "test_pred = []\n",
    "\n",
    "# 读入模型参数\n",
    "net.load_state_dict(torch.load('net_state.pkl'))\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    cur_pred = []\n",
    "    for i in range(100):\n",
    "        b_x = test_signals[i * 200: (i + 1) * 200]\n",
    "        output = nn.functional.softmax(net(b_x), dim=1).numpy().tolist()\n",
    "        cur_pred.extend(output)\n",
    "test_pred.append(cur_pred)\n",
    "\n",
    "# test_pred = np.array(test_pred)\n",
    "# test_avg = test_pred.mean(axis=0)\n",
    "# test_y_pred = test_avg.argmax(axis=1)\n",
    "# test_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-5f053dbf0436>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcur_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'mean'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[9.98525560e-01, 4.95368207e-04, 6.36133074e-04, 3.42902378e-04],\n",
       "        [2.23498605e-03, 3.06179048e-03, 9.93577719e-01, 1.12543185e-03],\n",
       "        [1.71101186e-03, 1.09001505e-03, 1.25909201e-03, 9.95939851e-01],\n",
       "        ...,\n",
       "        [8.27118475e-03, 3.87121947e-03, 9.86034751e-01, 1.82286615e-03],\n",
       "        [9.97383177e-01, 9.04604851e-04, 1.07321993e-03, 6.39071281e-04],\n",
       "        [3.64486307e-01, 3.80276069e-02, 1.14602380e-01, 4.82883692e-01]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.98525560e-01, 4.95368207e-04, 6.36133074e-04, 3.42902378e-04],\n",
       "       [2.23498605e-03, 3.06179048e-03, 9.93577719e-01, 1.12543185e-03],\n",
       "       [1.71101186e-03, 1.09001505e-03, 1.25909201e-03, 9.95939851e-01],\n",
       "       ...,\n",
       "       [8.27118475e-03, 3.87121947e-03, 9.86034751e-01, 1.82286615e-03],\n",
       "       [9.97383177e-01, 9.04604851e-04, 1.07321993e-03, 6.39071281e-04],\n",
       "       [3.64486307e-01, 3.80276069e-02, 1.14602380e-01, 4.82883692e-01]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.998526</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.000343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.003062</td>\n",
       "      <td>0.993578</td>\n",
       "      <td>0.001125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001711</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.995940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.998115</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.000556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.997998</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.000595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>0.997335</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.001075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>0.996882</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>0.000899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>0.008271</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.986035</td>\n",
       "      <td>0.001823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>0.997383</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.000639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0.364486</td>\n",
       "      <td>0.038028</td>\n",
       "      <td>0.114602</td>\n",
       "      <td>0.482884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3\n",
       "0      0.998526  0.000495  0.000636  0.000343\n",
       "1      0.002235  0.003062  0.993578  0.001125\n",
       "2      0.001711  0.001090  0.001259  0.995940\n",
       "3      0.998115  0.000588  0.000741  0.000556\n",
       "4      0.997998  0.000678  0.000729  0.000595\n",
       "...         ...       ...       ...       ...\n",
       "19995  0.997335  0.000738  0.000852  0.001075\n",
       "19996  0.996882  0.001026  0.001194  0.000899\n",
       "19997  0.008271  0.003871  0.986035  0.001823\n",
       "19998  0.997383  0.000905  0.001073  0.000639\n",
       "19999  0.364486  0.038028  0.114602  0.482884\n",
       "\n",
       "[20000 rows x 4 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = pd.DataFrame(test_avg)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label_0</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.998526</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.000343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.003062</td>\n",
       "      <td>0.993578</td>\n",
       "      <td>0.001125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.995940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>0.998115</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.000556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>0.997998</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.000595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>119995</td>\n",
       "      <td>0.997335</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.001075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>119996</td>\n",
       "      <td>0.996882</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>0.000899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>119997</td>\n",
       "      <td>0.008271</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.986035</td>\n",
       "      <td>0.001823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>119998</td>\n",
       "      <td>0.997383</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.000639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>119999</td>\n",
       "      <td>0.364486</td>\n",
       "      <td>0.038028</td>\n",
       "      <td>0.114602</td>\n",
       "      <td>0.482884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id   label_0   label_1   label_2   label_3\n",
       "0      100000  0.998526  0.000495  0.000636  0.000343\n",
       "1      100001  0.002235  0.003062  0.993578  0.001125\n",
       "2      100002  0.001711  0.001090  0.001259  0.995940\n",
       "3      100003  0.998115  0.000588  0.000741  0.000556\n",
       "4      100004  0.997998  0.000678  0.000729  0.000595\n",
       "...       ...       ...       ...       ...       ...\n",
       "19995  119995  0.997335  0.000738  0.000852  0.001075\n",
       "19996  119996  0.996882  0.001026  0.001194  0.000899\n",
       "19997  119997  0.008271  0.003871  0.986035  0.001823\n",
       "19998  119998  0.997383  0.000905  0.001073  0.000639\n",
       "19999  119999  0.364486  0.038028  0.114602  0.482884\n",
       "\n",
       "[20000 rows x 5 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=pd.read_csv(r'C:\\\\Users\\\\Jiananyuan\\\\Desktop\\\\QuickAccess\\\\DM_homework\\\\dataset\\\\sample_submit.csv')\n",
    "result['label_0']=pred[0]\n",
    "result['label_1']=pred[1]\n",
    "result['label_2']=pred[2]\n",
    "result['label_3']=pred[3]\n",
    "result.to_csv('submit.csv',index=False)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
