{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253325"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tsfresh as tsf\n",
    "import random\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "df = pd.read_csv(r'C:\\\\Users\\\\Jiananyuan\\Desktop\\\\QuickAccess\\\\DM_homework\\dataset\\\\train.csv')\n",
    "signals = df['heartbeat_signals'].str.split(',', expand=True)\n",
    "signals.insert(0, '', df['label'], allow_duplicates=False)\n",
    "col_names = ['label']\n",
    "for i in range(0, 205):\n",
    "    col_names.append('signal_' + str(i))\n",
    "signals.columns = col_names\n",
    "signals = pd.DataFrame(signals, dtype=np.float64)\n",
    "\n",
    "def signal_enhance(_signal, sigma=0.1):\n",
    "    scalingFactor = np.random.normal(loc=1.0, scale=sigma, size=(1, _signal.shape[1]))\n",
    "    noise = np.matmul(np.ones((_signal.shape[0], 1)), scalingFactor)\n",
    "    return _signal * noise\n",
    "\n",
    "idx_set = signals.query('label==1').index\n",
    "record_label_1 = signals.iloc[idx_set, :].reset_index(drop=True)\n",
    "enhanced_signal_label_1 = record_label_1\n",
    "for i in np.arange(16):\n",
    "    tmp_enhanced_signal_label_1 = signal_enhance(record_label_1)\n",
    "    enhanced_signal_label_1 = pd.concat((enhanced_signal_label_1, \n",
    "                                         tmp_enhanced_signal_label_1), axis=0).reset_index(drop=True)\n",
    "enhanced_signal_label_1['label'] = 1\n",
    "\n",
    "idx_set = signals.query('label==2').index\n",
    "record_label_2 = signals.iloc[idx_set, :].reset_index(drop=True)\n",
    "enhanced_signal_label_2 = record_label_2\n",
    "for i in np.arange(3):\n",
    "    tmp_enhanced_signal_label_2 = signal_enhance(record_label_2)\n",
    "    enhanced_signal_label_2 = pd.concat((enhanced_signal_label_2, tmp_enhanced_signal_label_2), axis=0).reset_index(\n",
    "        drop=True)\n",
    "enhanced_signal_label_2['label'] = 2\n",
    "\n",
    "idx_set = signals.query('label==3').index\n",
    "record_label_3 = signals.iloc[idx_set, :].reset_index(drop=True)\n",
    "enhanced_signal_label_3 = record_label_3\n",
    "for i in np.arange(3):\n",
    "    tmp_enhanced_signal_label_3 = signal_enhance(record_label_3)\n",
    "    enhanced_signal_label_3 = pd.concat((enhanced_signal_label_3, tmp_enhanced_signal_label_3), axis=0).reset_index(\n",
    "        drop=True)\n",
    "enhanced_signal_label_3['label'] = 3\n",
    "\n",
    "idx_set = signals.query('label==0').index\n",
    "record_label_0 = signals.iloc[idx_set, :].reset_index(drop=True)\n",
    "\n",
    "data_train = pd.concat([record_label_0, \n",
    "                        enhanced_signal_label_1, \n",
    "                        enhanced_signal_label_2, \n",
    "                        enhanced_signal_label_3], ignore_index=True)\n",
    "\n",
    "def remove_last_zero(_series):\n",
    "    nps = _series.to_numpy()\n",
    "    zero_begin_idxs = np.arange(nps.shape[0])\n",
    "    for i in np.arange(nps.shape[1])[::-1]:\n",
    "        idxs = np.where(nps[zero_begin_idxs, i] <= 1.e-5)[0]\n",
    "        if idxs.size > 0:\n",
    "            nps[zero_begin_idxs[idxs], i] = np.nan\n",
    "            zero_begin_idxs = zero_begin_idxs[idxs]\n",
    "        else:\n",
    "            break\n",
    "    return pd.DataFrame(nps[:, :], index=_series.index, columns=_series.columns[:])\n",
    "\n",
    "# data_train = remove_last_zero(data_train)\n",
    "\n",
    "# drop_idx = list(data_train.index)\n",
    "# drop_idx = random.sample(drop_idx, 3325)\n",
    "# data_train = data_train.drop(drop_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "data_train = shuffle(data_train)\n",
    "net_train_data = data_train.iloc[:, 1:].to_numpy()\n",
    "net_train_label = data_train.iloc[:, 0].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 205) (200000,) (53325, 205) (53325,)\n"
     ]
    }
   ],
   "source": [
    "train_set = data_train.iloc[:200000, :]\n",
    "test_set = data_train.iloc[200000:, :]\n",
    "\n",
    "train_x = train_set.iloc[:, 1:].to_numpy()\n",
    "train_y = train_set.iloc[:, 0].to_numpy()\n",
    "valid_x = test_set.iloc[:, 1:].to_numpy()\n",
    "valid_y = test_set.iloc[:, 0].to_numpy()\n",
    "\n",
    "# train_data = data_train.iloc[:, 1:]\n",
    "# train_label = data_train.iloc[:, 0]\n",
    "\n",
    "# train_data = data_train.iloc[:, 1:].stack()\n",
    "# train_data = train_data.reset_index()\n",
    "# train_data.rename(columns={\"level_0\": \"id\", \"level_1\": \"time\", 0: \"signals\"}, \n",
    "#                   inplace=True)\n",
    "# train_data[\"signals\"] = train_data[\"signals\"].astype(float)\n",
    "\n",
    "# train_data\n",
    "\n",
    "print(train_x.shape, train_y.shape, valid_x.shape, valid_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9912298 , 0.94353304, 0.7646773 , ...,        nan,        nan,\n",
       "               nan],\n",
       "       [0.9714822 , 0.92896875, 0.57293281, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [0.97579528, 0.93408847, 0.65963666, ...,        nan,        nan,\n",
       "               nan],\n",
       "       ...,\n",
       "       [0.88023307, 0.89468516, 0.89448266, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [0.71712964, 0.68011328, 0.63003724, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [0.84084461, 0.5637697 , 0.63639073, ...,        nan,        nan,\n",
       "               nan]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_label.values.tolist()\n",
    "# net_train_data = train_data.values\n",
    "# net_train_label = train_label.values\n",
    "# net_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=1,\n",
    "                out_channels=64,\n",
    "                kernel_size=7,\n",
    "                stride=1,\n",
    "                padding=3,\n",
    "            ),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, 5, 1, 2),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 256, 3, 1, 1), \n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(), \n",
    "            nn.Conv1d(256, 256, 3, 1, 1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(6400, 4096),\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(4096, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.fc3 = nn.Linear(64, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "#         print(x.size())\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import copy\n",
    "\n",
    "# 训练网络\n",
    "def train_net(net, train_loader, valid_loader, EPOCH=20, LR=1e-5):\n",
    "    # 交叉熵作为损失函数\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Adam 优化器\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=LR)\n",
    "    \n",
    "    # 保留准确率最高的模型\n",
    "    best_state = copy.deepcopy(net.state_dict())\n",
    "    best_acc = 0\n",
    "\n",
    "    for epoch in range(EPOCH):\n",
    "        net.train()\n",
    "        train_l = 0\n",
    "        train_num = 0\n",
    "        for b_x, b_y in train_loader:\n",
    "            output = net(b_x)\n",
    "            loss = loss_fn(output, b_y)\n",
    "            optimizer.zero_grad() \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_l += loss.cpu().item()\n",
    "            train_num += len(b_x)\n",
    "        \n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_l = 0\n",
    "            valid_num = 0\n",
    "            right_num = 0.\n",
    "            for b_x, b_y in valid_loader:\n",
    "                output = net(b_x)\n",
    "                loss = loss_fn(output, b_y)\n",
    "                valid_l += loss.cpu().item()\n",
    "\n",
    "                pred_y = torch.argmax(output, dim=1)\n",
    "                valid_num += len(b_x)\n",
    "                right_num += (pred_y == b_y).sum().item()\n",
    "        valid_acc = right_num / valid_num\n",
    "        if valid_acc >= best_acc:\n",
    "            best_acc = valid_acc\n",
    "            best_state = copy.deepcopy(net.state_dict())\n",
    "        print('Epoch {} | train_loss {:.2e} | valid_loss {:.2e} | acc {:f} | best_acc {:f}'.format(epoch + 1, train_l / train_num, valid_l / valid_num, valid_acc, best_acc))\n",
    "        \n",
    "    \n",
    "    return best_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\jiananyuan\\appdata\\roaming\\python\\python38\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\jiananyuan\\appdata\\roaming\\python\\python38\\site-packages (from imblearn) (0.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\jiananyuan\\appdata\\roaming\\python\\python38\\site-packages (from imbalanced-learn->imblearn) (1.2.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\jiananyuan\\appdata\\roaming\\python\\python38\\site-packages (from imbalanced-learn->imblearn) (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\jiananyuan\\appdata\\roaming\\python\\python38\\site-packages (from imbalanced-learn->imblearn) (1.19.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\jiananyuan\\appdata\\roaming\\python\\python38\\site-packages (from imbalanced-learn->imblearn) (1.10.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([257932, 1, 205]) torch.Size([257932]) torch.Size([25333, 1, 205]) torch.Size([25333])\n",
      "torch.Size([257932, 1, 205]) torch.Size([257932]) torch.Size([25333, 1, 205]) torch.Size([25333])\n",
      "torch.Size([257932, 1, 205]) torch.Size([257932]) torch.Size([25333, 1, 205]) torch.Size([25333])\n",
      "torch.Size([257932, 1, 205]) torch.Size([257932]) torch.Size([25333, 1, 205]) torch.Size([25333])\n",
      "torch.Size([257932, 1, 205]) torch.Size([257932]) torch.Size([25333, 1, 205]) torch.Size([25333])\n",
      "torch.Size([257936, 1, 205]) torch.Size([257936]) torch.Size([25332, 1, 205]) torch.Size([25332])\n",
      "torch.Size([257936, 1, 205]) torch.Size([257936]) torch.Size([25332, 1, 205]) torch.Size([25332])\n",
      "torch.Size([257932, 1, 205]) torch.Size([257932]) torch.Size([25332, 1, 205]) torch.Size([25332])\n",
      "torch.Size([257932, 1, 205]) torch.Size([257932]) torch.Size([25332, 1, 205]) torch.Size([25332])\n",
      "torch.Size([257932, 1, 205]) torch.Size([257932]) torch.Size([25332, 1, 205]) torch.Size([25332])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from torch.utils.data import TensorDataset\n",
    "import time\n",
    "net_states = []\n",
    "seed = 2023\n",
    "\n",
    "# 采用 10 折交叉验证，训练 10 个模型\n",
    "sk = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "for i, (train, valid) in enumerate(sk.split(net_train_data, net_train_label)):\n",
    "    x_train = net_train_data[train]\n",
    "    y_train = net_train_label[train]\n",
    "    x_valid = net_train_data[valid]\n",
    "    y_valid = net_train_label[valid]\n",
    "    \n",
    "    # # 对训练数据进行随机过采样\n",
    "    x_train, y_train = RandomOverSampler(random_state=seed).fit_resample(x_train, y_train)\n",
    "\n",
    "    x_train = torch.tensor(x_train, dtype=torch.float).unsqueeze(-2)\n",
    "    x_valid = torch.tensor(x_valid, dtype=torch.float).unsqueeze(-2)\n",
    "    y_train = torch.tensor(y_train, dtype=int)\n",
    "    y_valid = torch.tensor(y_valid, dtype=int)\n",
    "    \n",
    "    # train_loader = DataLoader(TensorDataset(x_train, y_train), batch_size=512, shuffle=True, num_workers=2)\n",
    "    # valid_loader = DataLoader(TensorDataset(x_valid, y_valid), batch_size=1024, shuffle=False)\n",
    "    \n",
    "    # print('\\nTraining {}th net. {}\\n'.format(i + 1, time.strftime('%H:%M:%S')))\n",
    "    # net = Net()\n",
    "    # s = train_net(net, train_loader, valid_loader, 30)\n",
    "    # net_states.append(s)\n",
    "    print(x_train.shape, y_train.shape, x_valid.shape, y_valid.shape)\n",
    "\n",
    "# 保存模型参数\n",
    "torch.save(net_states, 'net_state.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200000, 1, 205]) torch.Size([200000]) torch.Size([53325, 1, 205]) torch.Size([53325])\n",
      "\n",
      "Training 10th net. 13:22:00\n",
      "\n",
      "Epoch 1 | train_loss 5.94e-04 | valid_loss 1.98e-04 | acc 0.986442 | best_acc 0.986442\n",
      "Epoch 2 | train_loss 3.40e-04 | valid_loss 1.51e-04 | acc 0.992743 | best_acc 0.992743\n",
      "Epoch 3 | train_loss 2.66e-04 | valid_loss 1.24e-04 | acc 0.994955 | best_acc 0.994955\n",
      "Epoch 4 | train_loss 2.16e-04 | valid_loss 1.01e-04 | acc 0.995762 | best_acc 0.995762\n",
      "Epoch 5 | train_loss 1.78e-04 | valid_loss 8.68e-05 | acc 0.996643 | best_acc 0.996643\n",
      "Epoch 6 | train_loss 1.48e-04 | valid_loss 7.30e-05 | acc 0.996981 | best_acc 0.996981\n",
      "Epoch 7 | train_loss 1.25e-04 | valid_loss 6.13e-05 | acc 0.997506 | best_acc 0.997506\n",
      "Epoch 8 | train_loss 1.05e-04 | valid_loss 5.36e-05 | acc 0.997543 | best_acc 0.997543\n",
      "Epoch 9 | train_loss 8.92e-05 | valid_loss 4.48e-05 | acc 0.997731 | best_acc 0.997731\n",
      "Epoch 10 | train_loss 7.57e-05 | valid_loss 4.01e-05 | acc 0.997900 | best_acc 0.997900\n",
      "Epoch 11 | train_loss 6.46e-05 | valid_loss 3.45e-05 | acc 0.998068 | best_acc 0.998068\n",
      "Epoch 12 | train_loss 5.54e-05 | valid_loss 2.98e-05 | acc 0.998050 | best_acc 0.998068\n",
      "Epoch 13 | train_loss 4.75e-05 | valid_loss 2.78e-05 | acc 0.998031 | best_acc 0.998068\n",
      "Epoch 14 | train_loss 4.07e-05 | valid_loss 2.44e-05 | acc 0.998106 | best_acc 0.998106\n",
      "Epoch 15 | train_loss 3.52e-05 | valid_loss 2.23e-05 | acc 0.998125 | best_acc 0.998125\n",
      "Epoch 16 | train_loss 3.02e-05 | valid_loss 1.85e-05 | acc 0.998331 | best_acc 0.998331\n",
      "Epoch 17 | train_loss 2.59e-05 | valid_loss 1.68e-05 | acc 0.998368 | best_acc 0.998368\n",
      "Epoch 18 | train_loss 2.27e-05 | valid_loss 1.51e-05 | acc 0.998500 | best_acc 0.998500\n",
      "Epoch 19 | train_loss 1.94e-05 | valid_loss 1.40e-05 | acc 0.998350 | best_acc 0.998500\n",
      "Epoch 20 | train_loss 1.68e-05 | valid_loss 1.26e-05 | acc 0.998275 | best_acc 0.998500\n",
      "Epoch 21 | train_loss 1.46e-05 | valid_loss 1.17e-05 | acc 0.998425 | best_acc 0.998500\n",
      "Epoch 22 | train_loss 1.27e-05 | valid_loss 1.01e-05 | acc 0.998368 | best_acc 0.998500\n",
      "Epoch 23 | train_loss 1.08e-05 | valid_loss 9.30e-06 | acc 0.998462 | best_acc 0.998500\n",
      "Epoch 24 | train_loss 9.23e-06 | valid_loss 8.84e-06 | acc 0.998425 | best_acc 0.998500\n",
      "Epoch 25 | train_loss 8.06e-06 | valid_loss 8.02e-06 | acc 0.998519 | best_acc 0.998519\n",
      "Epoch 26 | train_loss 1.13e-05 | valid_loss 1.08e-05 | acc 0.997787 | best_acc 0.998519\n",
      "Epoch 27 | train_loss 7.05e-06 | valid_loss 6.97e-06 | acc 0.998425 | best_acc 0.998519\n",
      "Epoch 28 | train_loss 5.29e-06 | valid_loss 6.52e-06 | acc 0.998444 | best_acc 0.998519\n",
      "Epoch 29 | train_loss 4.53e-06 | valid_loss 6.14e-06 | acc 0.998425 | best_acc 0.998519\n",
      "Epoch 30 | train_loss 3.90e-06 | valid_loss 5.80e-06 | acc 0.998500 | best_acc 0.998519\n"
     ]
    }
   ],
   "source": [
    "seed = 2023\n",
    "\n",
    "# x_train, x_label = RandomOverSampler(random_state=seed).fit_resample(x_train, x_label)\n",
    "\n",
    "train_x = torch.tensor(train_x, dtype=torch.float).unsqueeze(-2)\n",
    "valid_x = torch.tensor(valid_x, dtype=torch.float).unsqueeze(-2)\n",
    "train_y = torch.tensor(train_y, dtype=int)\n",
    "valid_y = torch.tensor(valid_y, dtype=int)\n",
    "print(train_x.shape, train_y.shape, valid_x.shape, valid_y.shape)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(train_x, train_y), batch_size=512, shuffle=True, num_workers=2)\n",
    "valid_loader = DataLoader(TensorDataset(valid_x, valid_y), batch_size=1024, shuffle=False)\n",
    "\n",
    "print('\\nTraining {}th net. {}\\n'.format(i + 1, time.strftime('%H:%M:%S')))\n",
    "net = Net()\n",
    "s = train_net(net, train_loader, valid_loader, 30)\n",
    "torch.save(s, 'net_state.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99157137, 1.        , 0.63181634, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.60755331, 0.54170839, 0.3406944 , ..., 0.35057524, 0.35056459,\n",
       "        0.36387441],\n",
       "       [0.97527263, 0.67109652, 0.68675854, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.95174484, 0.91626113, 0.66752511, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.92766929, 0.67718982, 0.2429062 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.66532122, 0.52706411, 0.51666253, ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ****************** 以下生成 submit.csv 结果文件 ******************\n",
    "df = pd.read_csv(r'C:\\\\Users\\\\Jiananyuan\\Desktop\\\\QuickAccess\\\\DM_homework\\dataset\\\\testA.csv')\n",
    "test_signals = df['heartbeat_signals'].str.split(',', expand=True)\n",
    "col_names = []\n",
    "for i in range(0, 205):\n",
    "    col_names.append('signal_' + str(i))\n",
    "test_signals.columns = col_names\n",
    "test_signals = pd.DataFrame(test_signals, dtype=np.float64)\n",
    "# test_signals  =remove_last_zero(test_signals)\n",
    "\n",
    "test_signals = test_signals.to_numpy()\n",
    "test_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "conv1d() received an invalid combination of arguments - got (numpy.ndarray, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mnumpy.ndarray\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[32;1mint\u001b[0m)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mnumpy.ndarray\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[32;1mint\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-58f96c6164d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mb_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_signals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mcur_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-a89572083d72>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    295\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m--> 297\u001b[1;33m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    298\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: conv1d() received an invalid combination of arguments - got (numpy.ndarray, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mnumpy.ndarray\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[32;1mint\u001b[0m)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mnumpy.ndarray\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[32;1mint\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "test_pred = []\n",
    "\n",
    "# 读入模型参数\n",
    "net.load_state_dict(torch.load('net_state.pkl'))\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    cur_pred = []\n",
    "    for i in range(100):\n",
    "        b_x = test_signals[i * 200: (i + 1) * 200]\n",
    "        output = nn.functional.softmax(net(b_x), dim=1).tolist()\n",
    "        cur_pred.extend(output)\n",
    "test_pred.append(cur_pred)\n",
    "\n",
    "test_pred = np.array(test_pred)\n",
    "test_avg = test_pred.mean(axis=0)\n",
    "test_y_pred = test_avg.argmax(axis=1)\n",
    "test_y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
